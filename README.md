# Yimir Root Project

This repository serves as the foundational skeleton for general-purpose projects, meticulously designed to leverage the capabilities of the Gemini CLI. It incorporates best practices for project structure, data management, and AI-driven development, ensuring a robust and scalable starting point for any new initiative.

## Key Features

*   **Layered Context Files**: Configuration and operational guidelines are organized in a hierarchical manner (global → project → local), mirroring the Gemini CLI's resolution order. This provides a clear separation between immutable guard-rails and domain-specific overrides.
*   **ReAct Loop Integration**: The project structure and command conventions are designed to seamlessly integrate with Gemini's Reason-then-Act (ReAct) cycle, facilitating the easy addition of new tools and automated workflows.
*   **Structured Memory**: Utilizes YAML "context sheets" for role-based metadata, enabling agents to efficiently retrieve mission statements, policies, KPIs, and project states with single function calls.
*   **Context-Engineering Patterns**: Employs advanced context-engineering techniques to minimize hallucinations and maximize token efficiency, moving beyond ad-hoc prompt strings.
*   **Robust Data & Artifact Management**: Implements a clear separation between input data and generated artifacts, with dedicated public and private trees for secure and reproducible workflows.

## Directory & File Layout

```
└── yimir-root/
    ├── README.md                # Comprehensive human overview of the project
    ├── context/                 # Layered context files for various domains
    │   ├── org.yaml             # Organizational mission, values, HR policies
    │   ├── platform.yaml        # Platform Dev team glossary + live status
    │   └── ...                  # Any other domain-specific context sheets
    ├── data/                    # Input data for the project
    │   ├── public/              # Small, shareable CSV/JSON samples (tracked by Git)
    │   └── private/             # Raw dumps, CVs, PII (ignored by VCS, optionally DVC-tracked)
    ├── artifacts/               # Products generated by agents
    │   ├── public/              # Polished docs, reports, PDFs (tracked by Git, potentially LFS)
    │   └── private/             # Interim scratch, rejected outputs (ignored by VCS, optionally DVC-tracked)
    ├── scripts/                 # Helper shell/Python scripts (e.g., ETL, crawlers)
    ├── .gemini/                 # Gemini CLI configuration and resources
    │   ├── GEMINI.md            # Global instructions and guard-rails for Gemini CLI
    │   ├── examples/            # Few-shot examples per domain for AI agents
    │   ├── templates/           # Reusable output templates (JDs, task specs, etc.)
    │   ├── tools.yaml           # Declarative tool registry for ReAct
    │   └── memory/              # (Optional) Vector store or JSONL transcripts for long-term memory
    ├── .gitignore               # Specifies files and directories to be ignored by Git
    ├── dvc.yaml                 # (Optional) DVC configuration for tracking private blobs
    └── pyproject.toml           # Project metadata and dependencies (for Python projects)
```

## Data Hygiene and Versioning

This project adopts a robust strategy for data hygiene and large-file management:

*   **Public vs. Private Data**: `data/public` and `artifacts/public` are intended for small, shareable files that can be tracked directly by Git. `data/private` and `artifacts/private` are for sensitive or bulky data that should be ignored by Git and optionally managed with DVC (Data Version Control).
*   **Git LFS & DVC Integration**: For shareable data exceeding 10 MB, Git LFS is recommended to track pointers instead of large blobs. For private raw dumps, model checkpoints, or binary artifacts, DVC can be used to push data to external storage (e.g., S3), keeping the Git repository lean and compliant.
*   **Templated `.gitignore` and `dvc.yaml`**: Ensures consistent data hygiene and versioning practices across all forks of the project.

## Gemini CLI Execution Plan

To bootstrap and utilize this project with the Gemini CLI:

1.  **Initialize the Repository**:
    ```bash
    git init ymir-root && cd ymir-root
    gemini init        # Creates the .gemini skeleton
    mkdir -p context data/public data/private artifacts/public artifacts/private scripts
    # Copy GEMINI.md and other initial files as needed
    ```
2.  **Register Tools**: Define external tools (e.g., GitHub, Google Search) in `.gemini/tools.yaml` for use by AI agents.
3.  **Run First Agent Pass**: Execute Gemini CLI commands with specific prompts and context files.
    ```bash
    gemini run --prompt "Generate onboarding policy draft for interns" --context "context/org.yaml"
    ```
4.  **Forking for New Domains**: Easily create new forks for specific domains, adding domain-specific context files and examples.
5.  **CI Guard-rails**: Integrate `gemini validate-context` in pre-commit hooks and set up GitHub Actions to automate tasks like summarizing repository status.

## Maintenance & Scaling Tips

*   **Vector Memory**: Mount `~/.gemini/memory` as a LiteLLM-compatible store for longer retrospectives and cross-project context deduplication.
*   **Chunk Budgets**: Keep `body:` sections in context files concise (≤ 10 KB) to optimize token usage.
*   **Iterate Prompts**: Adopt a "write-audit-rewrite" loop for prompt tuning, utilizing Gemini CLI's `--debug` option to inspect the chain-of-thought.

## Next Steps

*   **Populate `context/org.yaml`**: Add your organization's mission, values, and relevant policies.
*   **Integrate Data Sources**: Set up scripts in `scripts/` for ETL, crawling, or data conversion.
*   **Experiment with Tools**: Add and configure new tools in `.gemini/tools.yaml` to extend Gemini's capabilities.

This `README.md` is designed to be a **live document**. The Gemini CLI is configured to **continuously update this `README.md`** whenever significant work is completed or project guidelines evolve, ensuring it always reflects the current state and best practices of the project.