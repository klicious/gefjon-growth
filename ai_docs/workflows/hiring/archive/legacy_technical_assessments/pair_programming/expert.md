# **◾ Expert Problem Set (stretch for senior candidates)**

| **ID** | **Theme** | **Skill Signals** |
| --- | --- | --- |
| **E-1** | Sliding-Window Duplicate Detector (Bloom) | Probabilistic DS, time buckets |
| **E-2** | Distributed Token-Bucket Rate-Limiter (Sim) | Concurrency, state replication |
| **E-3** | DAG Job Scheduler w/ Parallel Batches | Topo sort, critical-path calc |
| **E-4** | Order-Book Patch & Checksum | Delta replay, CRC32, state integrity |
| **E-5** | Latency-Aware FIFO Queue Simulator | Stochastic modeling, priority queues |

---

## **E-1 Sliding-Window Duplicate Detector**

### **Summary / Objective**

Implement DuplicateDetector(T,W) with add(event_id:str, ts:int) -> bool that returns **True only if event_id has not appeared in the last W seconds**. Use a time-segmented Bloom-filter ring buffer of T shards (e.g., 4).

### **Requirements**

| **Aspect** | **Detail** |
| --- | --- |
| **False-Positive OK** | ≤ 1 % fp if Bloom (m,k) chosen via formula. |
| **Time** | add O(k). Rotate shard when time > oldest_shard+W/T. |
| **Memory** | Fixed O(mT) bits. |
| **Edge** | Idempotent adds inside window return False. |

Candidate only needs to code core ring logic; may stub hash fn with xxhash64.

Visible example: add ids at ts 0,1,2 then at 61 (W=60) returns True again.

Hidden: rapid inserts, wraparound, fp threshold check.

---

## **E-2 Distributed Token-Bucket Rate-Limiter (Simulator)**

### **Objective**

Simulate N workers sharing a global token bucket (capacity, refill_rps). Provide function:

```
def simulate(workers:int, capacity:int, refill:int, calls:list[tuple[w_id,int]]) -> list[bool]:
    ...
```

Each entry (w_id, ts) is a request time (sec). Return list indicating **allowed**/denied per call.

Requirements:

- Central bucket state; all workers see same tokens.
- At time t, add refill*(t-last_ts) tokens up to capacity.
- Concurrency modelled by processing calls in given order for equal ts.

Visible example: capacity 2, refill 1, calls [ (0,0),(1,0),(0,0) ] → [T,T,F].

Hidden: long gaps, over-capacity bursts, many workers.

---

## **E-3 DAG Job Scheduler with Parallel Batches**

### **Objective**

Given DAG jobs (nodes) and edges deps, return list of **batches**—each batch may run in parallel—so that all dependencies of a job appear in earlier batches. Detect cycle.

```
def topo_batches(jobs:set[str], deps:list[tuple[str,str]]) -> list[list[str]] | None:
    ...
```

Outputs: [ ["A"], ["B","C"], ["D"] ].

Edge-cases: cycle → None, disconnected graph, 10 k nodes.

Hidden tests include: deep chain, huge fan-out, cycle of length 2.

---

## **E-4 Order-Book Patch & Checksum**

### **Objective**

Maintain level-2 book state from **snapshot** + delta patches:

```
{ "seq":int, "bids":[[p,q],...], "asks":[...], "checksum":int }
```

Apply patches in order (seq incremental). Verify CRC32 of book string "price:qty;..." matches checksum else throw ChecksumError.

Provide:

```
class OrderBook:
    def __init__(self, snapshot:dict): ...
    def apply(self, patch:dict): ...
```

Hidden tests: out-of-order seq, delete level (qty=0), checksum mismatch triggers rollback.

---

## **E-5 Latency-Aware FIFO Queue Simulator**

### **Objective**

Simulate matching engine queue with **exponential latency** per order (λ). Given arrivals [ (id, ts) ], emit **departure time** when order exits server.

Single-server FIFO, service time exp(λ) generated by deterministic formula service = -ln(hash(id)%1)/λ (makes unit testable).

```
def simulate_fifo(arrivals:list[tuple[str,int]], lambd:float) -> list[tuple[str,float]]:
    ...
```

Visible example: ids "a","b" at ts 0 produce depart d_a = service_a, d_b = max(ts_b, d_a)+service_b.

Hidden: arrivals during service, equal ids (hash repeat), λ near 0.

---

### **How to Deploy**

1. **Difficulty Bands**
    
    *Easy*: P4-P8
    
    *Intermediate*: I-1 … I-5
    
    *Expert*: E-1 … E-5
    
2. **Rotation** – keep 1–2 per difficulty live; swap quarterly to avoid leak fatigue.
3. **Time-box Guidance**
    - Intermediate: 45 min coding + 10 min tests
    - Expert: 45 min coding → accept partial but correct core; probe design trade-offs in debrief.