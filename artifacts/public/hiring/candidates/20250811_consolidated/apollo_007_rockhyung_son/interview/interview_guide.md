# Interview Guide: RockHyung Son

## Pre-Interview Preparation (15 minutes)
- [ ] Review candidate's screening report and take-home assignment
- [ ] Prepare BEI questions based on their performance optimization background
- [ ] Set up technical discussion environment

## Interview Structure (90 minutes total)

### 1. Opening & Introductions (10 minutes)
- Welcome and introductions
- Brief overview of Gefjon Growth and the role
- Explain interview structure and timeline

### 2. BEI Core Values Assessment (60 minutes)

#### Value Assessment Priority Matrix
**HIGH PRIORITY** (6 minutes each): Customer-Centric Craftsmanship, Integrity & Reliability, Collaboration & Knowledge-Sharing, Technical Excellence  
**MEDIUM PRIORITY** (4 minutes each): Data-Informed Iteration, Ownership & Proactivity, Security & Compliance First, Observability & Guardrails  
**STANDARD PRIORITY** (3 minutes each): Innovative Spirit, Continuous Learning & Mentorship

#### Value-by-Value BEI Questions

##### 1. Technical Excellence & Scalable Elegance - PROVEN EVIDENCE
**Focus**: Verification of performance optimization approach and architectural thinking  
**Time Allocation**: 6 minutes  
**Primary Question**: "I see you achieved 5× performance improvements by optimizing queries from ~1000ms to ~200ms. Tell me about a specific time when you had to choose between a quick fix and a more elegant, scalable solution. What was the situation, what factors did you consider, what actions did you take, and what were the results?"  
**Follow-up Probes**:
- "How did you identify the bottlenecks in the first place?"
- "What trade-offs did you consider when implementing the optimization?"
**What to Listen For**: System thinking, performance measurement, scalable architecture
**Red Flags**: Quick fixes without architectural consideration, no performance measurement

##### 2. Customer-Centric Craftsmanship - MISSING EVIDENCE
**Focus**: Discovery of user-focused thinking across different domains  
**Time Allocation**: 6 minutes  
**Primary Question**: "You've worked on very different systems - BBQ app, daycare system, and security/AI backends. Tell me about a specific project where you had to balance technical requirements with user needs. What was the situation, who were the end users, what actions did you take to understand their needs, and how did it impact the final solution?"  
**Follow-up Probes**:
- "How did you gather feedback from users in that domain?"
- "Describe a time when user feedback changed your technical approach"
**What to Listen For**: User empathy, stakeholder consideration, user feedback integration
**Red Flags**: Technology-first thinking, no user validation mentioned

##### 3. Ownership & Proactivity - SUGGESTED EVIDENCE
**Focus**: Exploration of initiative-taking and ownership across multiple domains  
**Time Allocation**: 4 minutes  
**Primary Question**: "You've worked across food delivery, childcare, and security domains. Tell me about a specific time when you took ownership of a problem that wasn't explicitly assigned to you. What was the situation, what drove you to take action, what specific actions did you take, and what were the results?"  
**Follow-up Probes**:
- "How did you coordinate with stakeholders during this initiative?"
- "What challenges did you face when working across different domains?"
**What to Listen For**: Initiative-taking, accountability, cross-domain adaptability
**Red Flags**: Waiting for direction, avoiding responsibility

##### 4. Observability & Guardrails - SUGGESTED EVIDENCE
**Focus**: Verification of monitoring philosophy through Sentry implementation  
**Time Allocation**: 4 minutes  
**Primary Question**: "I see you implemented Sentry logging systems. Walk me through a specific situation where you implemented monitoring that caught a problem before it became critical. What was the situation, what metrics did you choose to track, what actions did you take, and what were the results?"  
**Follow-up Probes**:
- "How do you decide which errors and metrics are most important to monitor?"
- "Tell me about a time when logging data changed your debugging approach"
**What to Listen For**: Proactive monitoring, operational excellence, data-driven operations
**Red Flags**: Reactive-only approach, no systematic monitoring strategy

##### 5. Data-Informed Iteration - PROVEN EVIDENCE
**Focus**: Verification of metrics-based performance optimization approach  
**Time Allocation**: 4 minutes  
**Primary Question**: "You mentioned using performance metrics to achieve 5× improvements. Describe the specific process you used to measure, analyze, and validate those performance gains. What was the situation, what data did you gather, how did you analyze it, and what was the outcome?"  
**Follow-up Probes**:
- "How do you typically establish performance baselines?"
- "Tell me about a time when data contradicted your initial performance assumptions"
**What to Listen For**: Evidence-based decision making, measurement focus, iterative improvement
**Red Flags**: Gut-feeling decisions, no measurement approach

##### 6. Integrity & Reliability - MISSING EVIDENCE
**Focus**: Discovery of ethical decision-making and commitment reliability  
**Time Allocation**: 6 minutes  
**Primary Question**: "Tell me about a challenging situation where you had to choose between meeting a deadline and maintaining quality or doing what was right. What was the situation, what pressures were you under, what actions did you take, and what were the results?"  
**Follow-up Probes**:
- "How do you handle situations where stakeholders ask for shortcuts?"
- "Describe a time when you had to deliver difficult news about technical debt or quality issues"
**What to Listen For**: Ethical decision-making, quality focus, honest communication
**Red Flags**: Cutting corners, unreliable commitments, avoiding difficult conversations

##### 7. Security & Compliance First - MISSING EVIDENCE
**Focus**: Discovery of security-conscious practices despite working on security/AI systems  
**Time Allocation**: 4 minutes  
**Primary Question**: "Despite working on security/AI backends, I'd like to understand your security mindset. Describe a specific time when you identified or addressed a security concern in a project. What was the situation, how did you identify the issue, what actions did you take, and what was the outcome?"  
**Follow-up Probes**:
- "How do you typically consider security when designing APIs and authentication systems?"
**What to Listen For**: Security awareness, proactive risk identification
**Red Flags**: Security as afterthought, no security considerations mentioned

##### 8. Collaboration & Knowledge-Sharing - MISSING EVIDENCE
**Focus**: Discovery of teamwork experiences and knowledge-sharing behaviors  
**Time Allocation**: 6 minutes  
**Primary Question**: "Tell me about a specific time when you had to work with a difficult team member or resolve a significant disagreement about technical direction. What was the situation, what actions did you take, and how did it turn out?"  
**Follow-up Probes**:
- "How do you typically share knowledge with teammates who are less experienced?"
- "Describe your approach to documentation when working across multiple domains"
**What to Listen For**: Conflict resolution, teaching ability, collaborative approach
**Red Flags**: Poor communication, knowledge hoarding, team conflicts

##### 9. Continuous Learning & Mentorship - SUGGESTED EVIDENCE
**Focus**: Verification of cross-stack adaptability and learning approach  
**Time Allocation**: 3 minutes  
**Primary Question**: "You've adapted across multiple technology stacks - Java/Spring, Node.js/NestJS, Python/Django. Tell me about a specific time when you had to quickly learn a new technology to complete a project. What was the situation, how did you approach learning, what actions did you take, and what were the results?"  
**Follow-up Probes**:
- "How do you stay current with new technologies across different domains?"
**What to Listen For**: Learning agility, teaching others, staying current with industry
**Red Flags**: Stagnant skills, reluctance to learn, no teaching examples

##### 10. Innovative Spirit - MISSING EVIDENCE
**Focus**: Discovery of creative problem-solving across different domains  
**Time Allocation**: 3 minutes  
**Primary Question**: "Tell me about a time when you came up with a creative or unconventional solution to a technical problem across your different projects. What was the situation, what made the standard approach insufficient, what innovative solution did you develop, and what were the results?"  
**Follow-up Probes**:
- "How do you balance innovation with reliability across different business domains?"
**What to Listen For**: Creative problem-solving, willingness to experiment, novel approaches
**Red Flags**: Always status-quo, fear of new approaches, no creative solutions

### 3. Technical Deep Dive (30 minutes)

#### Core Technical Questions:
Based on candidate's performance optimization and cross-domain experience:

**System Design & Performance**:
- "Walk me through how you would design a scalable task management API that needs to handle both high-performance requirements and complex business logic"
- "Based on your experience optimizing queries, how would you approach database design for a system that needs both OLTP and analytics workloads?"

**Cross-Domain Architecture**:
- "You've worked across very different domains. How would you design a system that needs to handle both real-time user interactions and batch processing?"
- "Describe your approach to monitoring and observability in a multi-service architecture"

### 4. Cultural Fit & Candidate Questions (20 minutes)
- Company culture discussion and team dynamics
- Encourage candidate questions about role, team, company
- Discuss next steps and timeline

## BEI Evaluation Framework

### Core Values Assessment (60% of evaluation)
**PRIMARY FOCUS VALUES** (24 points total - 6 points each):
- **Customer-Centric Craftsmanship**: Discovery of user-focused thinking across domains
- **Integrity & Reliability**: Discovery of ethical decision-making
- **Collaboration & Knowledge-Sharing**: Discovery of teamwork experiences
- **Technical Excellence**: Verification of performance optimization approach

**SECONDARY VALUES** (16 points total - 4 points each):
- **Data-Informed Iteration**: Verification of metrics-based decisions
- **Ownership & Proactivity**: Exploration of initiative-taking
- **Security & Compliance First**: Discovery despite security system experience
- **Observability & Guardrails**: Verification of monitoring practices

**STANDARD VALUES** (6 points total - 3 points each):
- **Innovative Spirit**: Discovery of creative problem-solving
- **Continuous Learning & Mentorship**: Verification of cross-stack adaptability

**Total BEI Score**: 46 points maximum

### Technical Competency (25% of evaluation)
- **System Design**: Architecture and scalability considerations (8 points)
- **Performance Optimization**: Query optimization and system performance (8 points)
- **Problem-Solving**: Technical approach and methodology (9 points)

### Communication & Behavioral Consistency (15% of evaluation)
- **STAR Response Quality**: Complete situation-task-action-results responses (10 points)
- **Behavioral Pattern Consistency**: Consistent values demonstration across questions (5 points)

**Total Evaluation Score**: 100 points maximum
**Hiring Threshold**: ≥75 points (Strong Hire: ≥85, Hire: 75-84, Lean Hire: 65-74)

---
*Interview guide prepared for: Hire candidate*
*Screening score: 7.2/10*
