# context/hiring_stages.yaml
# Comprehensive hiring process stages for Dunamis Capital Platform Development Team
# Updated to reflect current automation capabilities and 2025 H2 OKR alignment

metadata:
  version: "2.0"
  last_updated: "2025-01-08T00:00:00Z"
  purpose: "Define structured hiring stages supporting 32-day time-to-hire target"
  domain: "hr_processes"
  visibility: "public"
  dependencies: ["mission_vision_values.yaml", "platform_development_team.yaml"]
  schema_version: "1.0"

hiring_stages:
  - stage_id: "sourcing"
    name: "Candidate Sourcing & Attraction"
    description: "Identifying and attracting potential candidates through multiple channels"
    duration_days: "1-7"
    automation_level: "manual"
    key_activities:
      - "Job posting on relevant platforms"
      - "Network referrals and recommendations"
      - "University partnerships and recruiting events"
      - "Technical community engagement"
    success_criteria:
      - "Qualified candidate pipeline of 6+ candidates"
      - "Diverse candidate pool representation"
      - "Clear role requirements communication"
    
  - stage_id: "intake"
    name: "Candidate Intake & Profile Processing"
    description: "Automated processing of candidate submissions into structured profiles"
    duration_days: "1-2"
    automation_level: "fully_automated"
    key_activities:
      - "JSON candidate profile creation"
      - "Resume parsing and data extraction"
      - "Initial qualification screening"
      - "Dooray Task creation for tracking"
    success_criteria:
      - "Complete candidate profile generated"
      - "All required information captured"
      - "Tracking task created in Dooray"
    ai_agents_involved: ["intake_agent", "profile_processor"]
    
  - stage_id: "screening"
    name: "Platform Engineering Competency Screening"
    description: "AI-assisted evaluation against platform engineering competency framework with emphasis on AI orchestration potential"
    duration_days: "2-3"
    automation_level: "ai_assisted"
    key_activities:
      - "AI orchestration and collaboration potential assessment"
      - "Systems thinking and architectural capability evaluation"
      - "Critical thinking and problem-solving pattern analysis"
      - "Learning agility and adaptability indicators identification"
      - "Platform engineering experience evidence mapping"
      - "Traditional coding vs AI-assisted development capability differentiation"
    success_criteria:
      - "Competency framework scoring completed (4 categories)"
      - "AI collaboration potential identified and scored"
      - "Platform engineering role-fit assessment completed"
      - "Minimum threshold validation (70% overall, 75% AI orchestration)"
      - "Development potential and growth trajectory analysis"
      - "Platform Lead approval obtained"
    ai_agents_involved: ["platform_competency_evaluator", "ai_orchestration_analyzer", "learning_agility_assessor"]
    manual_approval_required: true
    approval_authority: "Platform Lead"
    competency_framework:
      ai_orchestration_collaboration: 35%
      systems_thinking_architecture: 30%
      critical_thinking_problem_solving: 20%
      continuous_learning_adaptability: 15%
    
  - stage_id: "assessment"
    name: "AI-Assisted Platform Engineering Assessment"
    description: "Platform-focused technical assessment emphasizing AI-assisted development capability and production system thinking"
    duration_days: "5-7"
    automation_level: "ai_assisted"
    key_activities:
      - "AI-assisted development challenge generation (candidates encouraged to use AI tools)"
      - "Platform architecture and system design scenarios"
      - "Production-readiness and operational excellence evaluation"
      - "AI collaboration and output validation assessment"
      - "Iterative improvement and learning capability measurement"
    success_criteria:
      - "Demonstrates effective AI tool utilization for development tasks"
      - "Shows platform and systems thinking in solution design"
      - "Exhibits production-ready development practices"
      - "Validates AI-generated solutions critically and effectively"
      - "Iterates and improves solutions through AI collaboration"
      - "Meets platform engineering competency minimum thresholds"
    ai_agents_involved: ["platform_assessment_generator", "ai_collaboration_evaluator", "production_readiness_analyzer"]
    manual_approval_required: true
    approval_authority: "Platform Lead"
    assessment_focus:
      ai_assisted_development: "Primary - candidates use AI tools throughout"
      platform_architecture: "System design and integration patterns"
      production_thinking: "Observability, security, scalability considerations"
      learning_iteration: "Improvement through AI collaboration cycles"
    
  - stage_id: "interview_preparation"
    name: "Enhanced Interview Kit Generation (v2.0)"
    description: "AI-powered creation of comprehensive interview materials with behavioral/technical separation"
    duration_days: "1-2"
    automation_level: "fully_automated"
    key_activities:
      - "Platform engineering competency gap analysis (4-category framework)"
      - "AI orchestration capability assessment document creation"
      - "Systems thinking and architecture evaluation planning"
      - "AI-assisted development simulation design"
      - "Production platform scenario generation"
      - "Learning agility and adaptability assessment framework"
    success_criteria:
      - "Complete platform engineering interview kit generated (<4 hours)"
      - "Competency gaps identified across all 4 categories"
      - "AI-assisted development simulation addresses identified gaps"
      - "System architecture challenges target platform thinking"
      - "Production scenarios test operational and critical thinking"
      - "Learning agility assessment captures adaptation potential"
      - "Clear competency-based evaluation framework established"
    ai_agents_involved: ["interview_generator_v2", "gap_analyzer", "project_scaffolder"]
    manual_approval_required: true
    approval_authority: "Platform Lead"
    platform_engineering_enhancements:
      - "4-category competency framework assessment"
      - "AI orchestration and collaboration evaluation"
      - "Systems thinking and architecture focus"
      - "Production platform scenario simulations"
      - "Learning agility and continuous improvement assessment"
      - "AI-assisted development capability measurement"
    
  - stage_id: "interviewing"
    name: "Hybrid BEI + Enhanced Technical Assessment"
    description: "Comprehensive interview combining traditional BEI core values assessment with enhanced AI-assisted technical evaluation"
    duration_days: "3-5"
    automation_level: "manual"
    key_activities:
      - "BEI Core Values Assessment (40 minutes) - STAR format questions for all 10 values"
      - "AI-Assisted Development Technical Assessment (25 minutes) - Hands-on AI collaboration"
      - "Platform Engineering Scenarios (25 minutes) - Systems thinking and architecture"
      - "Candidate Q&A and wrap-up (5 minutes)"
      - "Hybrid scoring combining core values (60%) and technical assessment (40%)"
    success_criteria:
      - "Complete BEI assessment covering all 10 core values with PROVEN/SUGGESTED/MISSING analysis"
      - "Enhanced technical assessment demonstrating AI collaboration and platform thinking"
      - "Minimum threshold validation (67% overall: 70% core values + 60% technical)"
      - "Evidence-based hire/no-hire recommendation preserving cultural alignment"
      - "Development potential identified for both behavioral and technical growth"
    interview_structure:
      - session: "Introduction & Warm-up"
        duration: "5 minutes"
        focus: "Welcome, company overview, interview structure explanation"
        methodology: "Standard welcoming script with personalized opening referencing candidate achievements"
        
      - session: "BEI Core Values Assessment"
        duration: "40 minutes"
        focus: "Systematic assessment of all 10 core values using STAR methodology"
        methodology: "Traditional BEI with PROVEN/SUGGESTED/MISSING framework, prioritizing values with no evidence"
        core_values_coverage:
          - "Technical Excellence & Scalable Elegance"
          - "Customer-Centric Craftsmanship"
          - "Ownership & Proactivity" 
          - "Observability & Guardrails"
          - "Data-Informed Iteration"
          - "Integrity & Reliability"
          - "Security & Compliance First"
          - "Collaboration & Knowledge-Sharing"
          - "Continuous Learning & Mentorship"
          - "Innovative Spirit"
          
      - session: "AI-Assisted Technical Assessment"
        duration: "25 minutes"
        focus: "AI collaboration effectiveness and platform development capability"
        methodology: "Hands-on simulation with AI tools available (Claude, ChatGPT, Copilot)"
        technical_focus: "Platform service enhancement using AI assistance with authentication, monitoring, scaling"
        
      - session: "Platform Engineering Scenarios"  
        duration: "25 minutes"
        focus: "Systems thinking, architecture design, and production problem-solving"
        methodology: "Architecture discussion and production scenario problem-solving"
        scenarios: "10x scaling challenge, latency troubleshooting, cross-system integration"
        
      - session: "Candidate Q&A"
        duration: "5 minutes"
        focus: "Candidate questions and final clarifications"
        
      hybrid_approach_benefits:
        - "Preserves organizational DNA through complete core values assessment"
        - "Maintains BEI methodology and STAR format proven effectiveness"
        - "Enhances technical evaluation for AI-assisted development reality"
        - "Addresses Phoenix_005 type cases while maintaining cultural alignment"
        - "Combines behavioral excellence with platform engineering capability"
    
  - stage_id: "evaluation"
    name: "Comprehensive Candidate Evaluation"
    description: "Aggregated evaluation and final hiring recommendation"
    duration_days: "2-3"
    automation_level: "ai_assisted"
    key_activities:
      - "Multi-stage evaluation aggregation"
      - "Scoring consistency validation"
      - "Final recommendation generation"
      - "Risk assessment and mitigation"
    success_criteria:
      - "Comprehensive evaluation report completed"
      - "Clear hire/no-hire recommendation"
      - "Risk factors identified and assessed"
      - "Salary band recommendation provided"
    ai_agents_involved: ["evaluation_aggregator", "decision_synthesizer"]
    manual_approval_required: true
    approval_authority: "Platform Lead"
    
  - stage_id: "decision"
    name: "Final Hiring Decision"
    description: "Executive decision and offer preparation"
    duration_days: "2-3"
    automation_level: "manual"
    key_activities:
      - "Final decision review and approval"
      - "Offer package preparation"
      - "Reference checks (if required)"
      - "Background verification initiation"
    success_criteria:
      - "Final hiring decision documented"
      - "Offer terms approved and prepared"
      - "All compliance requirements met"
    decision_authority: "Platform Lead"
    escalation_path: "Engineering Manager"
    
  - stage_id: "offer"
    name: "Offer Extension & Negotiation"
    description: "Formal offer presentation and negotiation process"
    duration_days: "5-10"
    automation_level: "manual"
    key_activities:
      - "Offer presentation to candidate"
      - "Negotiation and terms adjustment"
      - "Contract preparation and review"
      - "Onboarding preparation"
    success_criteria:
      - "Offer accepted by candidate"
      - "Contract signed and executed"
      - "Start date confirmed"
      - "Onboarding plan activated"

# Process Performance Metrics
performance_metrics:
  current_baseline:
    time_to_hire_days: 32
    candidates_per_month: 40
    peak_capacity_per_week: 15
    interview_kit_generation_hours: 4
    
  target_improvements:
    automation_coverage: "90%"
    manual_intervention_time: "<20 minutes per candidate"
    interview_consistency: ">90%"
    quality_satisfaction: "≥4.0/5.0"
    
  success_kpis:
    - metric: "Time to Interview Kit"
      target: "<4 hours"
      current: "manual baseline"
    - metric: "Interview Consistency"
      target: "≥90%"
      measurement: "structured question coverage"
    - metric: "Quality Score"
      target: "≥4.0/5.0"
      measurement: "interviewer satisfaction"
    - metric: "Cost per Hire"
      target: "<$75"
      measurement: "automation cost per candidate"

# Integration Points
integration_points:
  dooray_task:
    purpose: "Task creation and workflow management"
    automation: "PyDooray API integration"
    templates: ["backend_task", "frontend_task", "devops_task"]
    
  ai_agents:
    primary_llm: "Gemini 2.5 Pro"
    fallback_models: ["Claude 3.5 Sonnet", "GPT-4o", "ChatGPT-4o", "Amazon Q Developer"]
    cost_optimization: "batch processing, smart caching, quality-optimal token usage"
    enhanced_capabilities: "improved reasoning, multimodal processing, quality-optimized context delivery"
    
  monitoring:
    platform: "Grafana Cloud + Prometheus"
    golden_signals: ["latency", "error_rate", "availability"]
    alerting: "Notion API → Zapier → Slack"

# Quality Assurance Framework
quality_framework:
  validation_stages:
    - "Schema validation"
    - "Consistency check"
    - "AI content review"
    - "Cross-domain validation"
    - "Quality scoring"
    - "Final approval"
    
  approval_gates:
    - stage: "screening"
      approver: "Platform Lead"
      criteria: "Core values alignment validation"
    - stage: "assessment"
      approver: "Platform Lead"
      criteria: "Technical assessment appropriateness"
    - stage: "interview_preparation"
      approver: "Platform Lead"
      criteria: "Interview material quality and relevance"
    - stage: "evaluation"
      approver: "Platform Lead"
      criteria: "Final hiring recommendation validation"

# AI Agent Instructions
ai_agent_instructions:
  context_usage: "Use this hiring stages framework to guide candidate processing workflows and ensure consistent evaluation standards"
  update_triggers: ["process_improvements", "okr_changes", "team_structure_updates"]
  quality_standards: "Maintain alignment with 10 core values and 2025 H2 OKR targets"
